\section{Constructing invariants}
\label{sec:constructing_invariants}

We now show that one can compute inductive invariants from the method
\safetyref.
That is, given a Petri net $N=(P,T,F,m_0)$ and a property $\varphi$, if
\safetyref{} (over the rationals) can prove $N$ satisfies $\varphi$, then in fact we can construct a linear inductive invariant
that contains $m_0$ and does not intersect $\lnot\varphi$. We call the
new method \invariantref.

The key observation is to use a constraint system dual to the constraint system for \safetyref.
%
% We make a simple observation which, combined with the flexibility of
% SMT-solvers, leads to an interesting improvement on the method \safetyref.
% We propose method \invariantref\ with the same power as the
% method \safetyref\ over the rational numbers, but dual to it: the
% constraints of method \safetyref\ are infeasible over the rational
% numbers if{}f the constraints of method \invariantref\ are
% feasible. 
% The advantage is that the solution delivered by the
% method \invariantref\ is an inductive linear invariant satisfied by all
% reachable markings, but violated by all markings that do not satisfy
% the property. 
% So this invariant provides an \emph{explanation} of why
% the property holds.
We assume $\varphi$ is a co-linear property, i.e.,~the negation $\lnot\varphi$ is
represented as the constraints:
 $$\neg \varphi\  :: \ A M \ge b$$
where $A$ is a $k\times |P|$ matrix, and $b$ is a $k\times 1$ vector, for some
$k\geq 1$. Furthermore, we assume that there are $l\geq 0$ trap
constraints~\eqref{eq:trapcons}, which are collected in matrix form $D M \geq
1$, for an $l\times |P|$ matrix $D$, and an $l\times 1$ vector of ones, denoted
simply by $1$.
% consider the matrix form of the trap constraints $C_T$ below
% $$ C_T = ( D M \ge 1 ) $$
% for some matrix $D$.

We use the following version of Farkas' Lemma:

\begin{lemma}[Farkas' Lemma (variant)~\cite{Schrijver86}]
\label{lem:farkas}
Let $A$ be a matrix and let $b$ be a vector.
Then the system $Ax \le b$ of linear inequalities has a solution $x$,
if and only if there is no row vector $y \ge 0$ with $yA = 0$ and $yb < 0$.
\end{lemma}

Consider the following primal system $\mathcal{S}$:
\begin{align*}
  & \mathcal{C}(P, T, F, m_0)  && \text{marking constraints} \\
  & A M \ge b                 && \text{negation of property $\varphi$} \\
  & D M \ge 1                 && \text{trap constraints}
\end{align*}
%

By transforming $\mathcal{S}$ into a suitable form and applying 
Lemma~\ref{lem:farkas}, we get the following theorem.

\begin{theorem}
\label{thm:dual}
The primal system $\mathcal{S}$ is unsatisfiable over the rational numbers if
and only if the following dual system $\mathcal{S}'$ is satisfiable over the
rational numbers.
\begin{align*}
  \lambda C    & \le 0            && \text{inductivity constraint} \\
  \lambda m_0  & <   Y_1 b + Y_2 1 && \text{safety constraint} \\
  \lambda      & \ge Y_1 A + Y_2 D && \text{property constraint} \\
  Y_1, Y_2     & \ge 0     && \text{non-negativity constraint} 
\end{align*}
Here $\lambda$, $Y_1$ and $Y_2$ are vectors of variables of size $1\times |P|$,
$1\times k$ and $1\times l$, respectively.
\end{theorem}

\begin{proof}
Recall that the system $\mathcal{S}$ is given by:
\begin{align*}
  \mathcal{C}&(P, T, F, m_0)  && \text{state constraints} \\
  A M & \ge b                 && \text{negation of property $P$} \\
  D M & \ge 1                 && \text{trap constraints}
\end{align*}
Eliminating $M$ we get
\begin{align*}
A (m_0 + C X) & \ge b && \text{property $P$ negated} \\
D (m_0 + C X) & \ge 1 && \text{trap constraints} \\
   m_0 + C X  & \ge 0 && \text{non-negativity conditions for places} \\
           X  & \ge 0 && \text{non-negativity conditions for transitions}
\end{align*}
which can be rewritten in matrix form as
%
\begin{align*}
\begin{pmatrix}
  -  A  C \\
  -  D  C \\
  -     C \\
  -     I
\end{pmatrix} X & \le
\begin{pmatrix}
  A m_0 - b \\
  D m_0 - 1 \\
    m_0     \\
     0
\end{pmatrix}
\end{align*}
%
Lemma~\ref{lem:farkas} yields the set $\mathcal{S}_1$ given by  
%
\begin{align*}
  Y^T
\begin{pmatrix}
  -  A  C \\
  -  D  C \\
  -     C \\
  -     I
\end{pmatrix} & = 0  &
  Y^T
\begin{pmatrix}
  A m_0 - b \\
  D m_0 - 1 \\
    m_0     \\
     0
\end{pmatrix} & < 0  &
Y & \ge 0
\end{align*}
So, by the Lemma, $\mathcal{S}_1$ is satisfiable if and only if $\mathcal{S}$ is unsatisfiable. 
Splitting the vector $Y$ into four segments $Y := (Y_1|Y_2|Y_3|Y_4)$ 
we obtain that $\mathcal{S}_1$ is equisatisfiable with 
\begin{align*}
  Y_1 A C         + Y_2 D C         + Y_3 C  + Y_4    & = 0 \\
  Y_1 (A m_0 - b) + Y_2 (D m_0 - 1) + Y_3 m_0         & < 0 \\
  Y_i                               & \ge 0 \ \ i=1,2,3,4
\end{align*}
and, since $Y_4\ge 0$ is only requiring that $Y_1 D C + Y_2 A C + Y_3 C \leq 0$ holds,
also with 
\begin{align*}
  (Y_1 A + Y_2 D + Y_3) C    & \le 0          \\
  (Y_1 A + Y_2 D + Y_3) m_0  & < Y_1 b + Y_2 1 \\
  Y_1,Y_2,Y_3 & \ge 0 
\end{align*}
Finally, defining $\lambda := Y_1 A + Y_2 D + Y_3$, we obtain that
$\mathcal{S}_1$ is equisatisfiable with $\mathcal{S}'$:
\begin{align*}
  \lambda C    & \le 0             \\
  \lambda m_0  & <   Y_1 b + Y_2 1  \\
  \lambda      & \ge Y_1 A + Y_2 D  \\
  Y_1, Y_2        & \ge 0    
\end{align*}
\end{proof}


If the primal system $\mathcal{S}$ is unsatisfiable, we can take $\lambda$ from
a solution to $\mathcal{S}'$ and construct an inductive invariant:
$$I(M)\  ::= \  DM\geq 1 \land \lambda M \leq \lambda m_0\,.$$

In order to show that $I(M)$ is an invariant, recall that for every reachable
marking $m$ there is a solution to $m = m_0 + CX$, with $X\geq 0$. Multiplying
by $\lambda$ and taking into account that $\lambda$ is a solution to $\mathcal{S}'$, we get 
$$\lambda m = \lambda m_0 + \lambda CX \leq \lambda m_0\,.$$
Furthermore, every reachable marking satisfies the trap constraints $DM\geq 1$.
On the other hand, a marking $m$ that violates the property $\varphi$ does
not satisfy $I(M)$, for it either does not satisfy $DM\geq 1$, or both
$Am\geq b$ and $Dm\geq 1$ hold. But in the latter case we have
$$\lambda m \geq (Y_1 A + Y_2 D)m = Y_1 A m + Y_2 D m \geq
Y_1 b + Y_2 1 > \lambda m_0\,.$$
%

In order to show that $I(M)$ is inductive, we have to show that if
$I(m)$ holds for some marking $m$ (reachable or not), and $m \xrightarrow{t} m'$
for some transition $t$, then $I(m')$ holds as well. Indeed, in this case we
have $m' = m + C e_t$, where $e_t$ is the unit vector with $1$ in the $t$-th
component and $0$ elsewhere.
% $e_t = (0,\ldots,0,\underbrace{1}_{t},0,\ldots,0)^T$ is the vector whose
% components are all $0$ but the one corresponding to $t$, which has value $1$.
Hence
$$\lambda m' = \lambda(m + Ce_t) = \lambda m + \lambda Ce_t
\le \lambda m \le \lambda m_0\,,$$
and furthermore, as $m$ satisfies the trap constraints, $m'$ also satisfies
them.

So far, we have assumed that property $\varphi$ is a co-linear property.
However, it is easy to extend the method to the case when
$\varphi=\varphi_1\land\ldots\land\varphi_r$, and each $\varphi_i$ is a
co-linear property. In that case, for each $\varphi_i$ we invoke \invariantref{}
to obtain an inductive invariant $I_i$. One can easily verify that
$I_1\land\ldots\land I_r$ is an inductive invariant with respect to $\varphi$.
